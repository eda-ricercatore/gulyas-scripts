#	Workshop on Parallel AI and Systems for the Edge

From: https://www.sigarch.org/call-contributions/workshop-on-parallel-ai-and-systems-for-the-edge/

1st Workshop on Parallel AI and Systems for the Edge (PAISE)
in conjunction with IPDPS 2019
Rio de Janeiro, Brazil
May 24, 2019

IMPORTANT DATES:
Submission deadline: February 1, 2019
Notification of acceptance: March 1, 2019:
Workshop camera-ready papers due: March 11, 2019

For this workshop we welcome original work covering different aspects of:
1.Edge Inference
2.Hardware for Edge-computing and Machine Learning
3.Energy Efficient Processors for Training and Inference
4.Computer Vision at the Edge
5.Cyber Security for Edge Computing
6.Software and Hardware Multitenancy at the Edge
7.Machine Learning Hardware
8.Blockchains for Edge Computing
9.Programming Models for Edge Computing
10.Coupling HPC to Edge Applications
11.Communication and Control Strategies for Deploying and Managing Applications at the Edge

SUBMISSION GUIDELINES:
All papers must be original and not simultaneously submitted to another journal or conference. The papers submitted to the workshop will be peer reviewed by a minimum of 3 reviewers.

The following paper categories are welcome:
– Full Papers: Research papers should describe original work and be 8 or 10 pages in length.
– Short Papers: Short research papers, 4 pages in length, should contain enough information for the program committee to understand the scope of the project and evaluate the novelty of the problem or approach.
– Emerging Platforms and Practitioner Reports: Short reports, 3-6 pages in length, describing novel hardware and Software platforms, including initial proof-of-concept design and implementation are welcome. Reports may also focus on a particular aspect of technology usage in practice, or describe broad project experiences. They may describe a particular design idea, or experience with a particular piece of technology.

Templates for MS Word and LaTeX provided by IEEE eXpress Conference Publishing are available for download. See the latest versions here: https://www.ieee.org/conferences_events/conferences/publishing/templates.html

Upload your submission to EasyChair submission server in PDF format. EasyChair URL: https://easychair.org/cfp/PAISE2019.
Accepted manuscripts will be included in the IPDPS workshop proceedings.

ORGANIZERS:
Pete Beckman, Argonne National Laboratory, USA
Rajesh Sankaran, Argonne National Laboratory, USA


##	From the official web page

From: https://www.mcs.anl.gov/research/projects/waggle/cfp/PAISE2019.html

Applications involving voluminous data but needing low-latency computation and local feedback require that the computing be performed as close to the data source as possible --- often at the interface to the physical world. Communication constraints and the need for privacy-preserving approaches also dictate the need for computing at the edge. Given the growth in such application scenarios and the recent advances in algorithms and techniques, machine learning and inference at the edge are unfolding and growing at a rapid pace. In support of these applications, a wide range of hardware (CPUs, GPUs, ASICs) is venturing farther away from the center, closer to the physical world. The resulting diversity in edge-computing hardware in terms of capabilities, architectures, and programming models poses several new challenges.

At the edge, several applications often need to be scheduled concurrently or serially. Some applications may need to be run continuously, a few in anticipation of certain events, whereas others may need to be run when particular events occur, causing a need to unload other applications and dedicate resources to them. Situations may also warrant running applications in sandboxes for privacy, security, and resource allocation reasons. A future with heterogeneous edge hardware and multiple applications sharing the hardware and energy resources is imminent.

Deploying and managing applications at the edge remotely, and building in multienancy to support applications with various resource constraints and runtime requirements, present a challenge that requires cooperation and coordination between the various components of the software stack. Mechanisms need to be devised that communicate both data and control with the applications in order to fine-tune their behavior and change the operational parameters. Coupling these edge applications with centrally located HPC resources and their applications, realizing the computing continuum, also opens up many research areas.

As we push more toward edge-enabled networks of devices, we inherit a setting where resources are deployed away from the safety of secure indoor spaces, often in the midst of a bustling urban canyon, and exposed to physical and cybersecurity threats. Deployed and interconnected predominantly over public networks, these systems have to be designed with cybersecurity as a first-class design citizen, rather than introduced as an afterthought.

The goal of this workshop is to gather the community working in three broad areas:

+ processing — artificial intelligence, computer vision, machine learning;
+ management — parallel and distributed programming models for resource-constrained and domain-specific hardware, containers, remote resource management, runtime-system design, and cybersecurity; and
+ hardware — systems and devices conducive to use in resource-constrained (energy, space, etc.) applications.

The workshop will provide a critically needed opportunity to discuss the current trends and issues, to share visions, and to present solutions.

Topics

For this workshop we welcome original work covering different aspects of:

+ Edge Inference
+ Hardware for Edge-computing and Machine Learning
+ Energy Efficient Processors for Training and Inference
+ Computer Vision at the Edge
+ Cyber Security for Edge Computing
+ Software and Hardware Multitenancy at the Edge
+ Machine Learning Hardware
+ Blockchains for Edge Computing
+ Programming Models for Edge Computing
+ Coupling HPC to Edge Applications
+ Communication and Control Strategies for Deploying and Managing Applications at the Edge



#	FastPath: Workshop on Performance Analysis of Machine Learning Systems

https://www.sigarch.org/call-contributions/workshop-on-performance-analysis-of-machine-learning-systems/

Call for Papers:
FastPath: Workshop on Performance Analysis of Machine Learning Systems

March 24, 2019 in Madison, Wisconsin, USA
URL: https://tinyurl.com/2019-FastPath
Abstract or Paper Registration Deadline
February 8, 2019
Final Submission Deadline
February 8, 2019

FastPath: International Workshop on Performance Analysis of Machine Learning Systems
in conjunction with ISPASS 2019
Madison, Wisconsin, USA
March 24, 2019

FastPath 2019 brings together researchers and practitioners involved in cross-stack hardware/software performance analysis, modeling, and evaluation for efficient machine learning systems. Machine learning demands tremendous amount of computing. Current machine learning systems are diverse, including cellphones, high performance computing systems, database systems, self-driving cars, robotics, and in-home appliances. Many machine-learning systems have customized hardware and/or software. The types and components of such systems vary, but a partial list includes traditional CPUs assisted with accelerators (ASICs, FPGAs, GPUs), memory accelerators, I/O accelerators, hybrid systems, converged infrastructure, and IT appliances. Designing efficient machine learning systems poses several challenges.

These include distributed training on big data, hyper-parameter tuning for models, emerging accelerators, fast I/O for random inputs, approximate computing for training and inference, programming models for a diverse machine-learning workloads, high-bandwidth interconnect, efficient mapping of processing logic on hardware, and cross system stack performance optimization. Emerging infrastructure supporting big data analytics, cognitive computing, large-scale machine learning, mobile computing, and internet-of-things, exemplify system designs optimized for machine learning at large.

FastPath seeks to facilitate the exchange of ideas on performance optimization of machine learning/AI systems and seeks papers on a wide range of topics including, but not limited to:
– Workload characterization, performance modeling and profiling of machine learning applications
– GPUs, FPGAs, ASIC accelerators
– Memory, I/O, storage, network accelerators
– Hardware/software co-design
– Efficient machine learning algorithms
– Approximate computing in machine learning
– Power/Energy and learning acceleration
– Software, library, and runtime for machine learning systems
– Workload scheduling and orchestration
– Machine learning in cloud systems
– Large-scale machine learning systems
– Emerging intelligent/cognitive system
– Converged/integrated infrastructure
– Machine learning systems for specific domains, e.g., financial, biological, education, commerce, healthcare

SUBMISSION GUIDELINES:
Prospective authors must submit a 2-4 page extended abstract electronically at: https://easychair.org/conferences/?conf=fastpath2019

Authors of selected abstracts will be invited to give a 30-min presentation at the workshop.

IMPORTANT DATES:
Submission: February 8, 2019
Notification: February 22, 2019
Final Materials / Workshop: March 24, 2019

ORGANIZERS:
General Chair:
Erik Altman

Program Committee Chairs:
Zehra Sura
Parijat Dube


##	From the Official Web Page

https://researcher.watson.ibm.com/researcher/view_group.php?id=9888

FastPath 2019
International Workshop on Performance
Analysis of Machine Learning Systems
March 24, 2019 - Madison, Wisconsin, USA
In conjunction with ISPASS 2019
https://tinyurl.com/2019-FastPath

FastPath 2019 Program:  Pending

FastPath 2019 brings together researchers and practitioners involved in cross-stack hardware/software performance analysis, modeling, and evaluation for efficient machine learning systems. Machine learning demands tremendous amount of computing. Current machine learning systems are diverse, including cellphones, high performance computing systems, database systems, self-driving cars, robotics, and in-home appliances. Many machine-learning systems have customized hardware and/or software. The types and components of such systems vary, but a partial list includes traditional CPUs assisted with accelerators (ASICs, FPGAs, GPUs), memory accelerators, I/O accelerators, hybrid systems, converged infrastructure, and IT appliances. Designing efficient machine learning systems poses several challenges.

These include distributed training on big data, hyper-parameter tuning for models, emerging accelerators, fast I/O for random inputs, approximate computing for training and inference, programming models for a diverse machine-learning workloads, high-bandwidth interconnect, efficient mapping of processing logic on hardware, and cross system stack performance optimization. Emerging infrastructure supporting big data analytics, cognitive computing, large-scale machine learning, mobile computing, and internet-of-things, exemplify system designs optimized for machine learning at large.


Topics

FastPath seeks to facilitate the exchange of ideas on performance analysis and evaluation of machine learning/AI systems and seeks papers on a wide range of topics including, but not limited to:

+ Workload characterization, performance modeling and profiling of machine
+ learning applications
+ GPUs, FPGAs, ASIC accelerators
+ Memory, I/O, storage, network accelerators
+ Hardware/software co-design
+ Efficient machine learning algorithms
+ Approximate computing in machine learning
+ Power/Energy and learning acceleration

+ Software, library, and runtime for machine learning systems
+ Workload scheduling and orchestration
+ Machine learning in cloud systems
+ Large-scale machine learning systems
+ Emerging intelligent/cognitive systems
+ Converged/integrated infrastructure
+ Machine learning systems for specific domains, e.g., financial, biological, education, commerce, healthcare


Submission

FastPath 2019 Call for Papers is available here.

Prospective authors must submit a 2-4 page extended abstract electronically at:

https://easychair.org/conferences/?conf=fastpath2019

Authors of selected abstracts will be invited to give a 30-min presentation at the workshop.


Key Dates

+ Submission: February 8, 2019
+ Notification: February 22, 2019
+ Final Materials / Workshop: March 24, 2019


Organizers

+ General Chair: Erik Altman (IBM)
+ Program Committee Chairs: Zehra Sura (IBM), Parijat Dube (IBM)


Program Committee
TBD: TBD Institution

Invited Speakers:

Tushar Krishna: Georgia Tech

Peter Mattson: Google

Vijay Janapa Reddi: Harvard


Previous Editions

FastPath 2018 was held in conjunction with ISPASS 2018. Full-day with 4 invited speakers and panel.

FastPath 2015 was held in conjunction with ISPASS 2015. Half-day with 4 invited speakers.

FastPath 2014 was held in conjunction with ISPASS 2014. Full-day with 3 invited speakers and 4 Regular speaker.

FastPath 2013 was held in conjunction with ISPASS 2013. Full-day with 1 keynote speaker, 6 invited speakers and 1 Regular speaker.

FastPath 2012 was held in conjunction with ISPASS 2012. Half-day with 1 keynote speaker and 3 invited speakers.



#	Workshop on Attacks and Solutions in Hardware Security (ASHES 2019)

+ Fault injection, side channels, hardware Trojans, and countermeasures
+ Tamper sensing and tamper protection
+ New physical attack vectors or methods
+ Biometrics
+ Secure sensors
+ Device fingerprinting and hardware forensics
+ Lightweight hardware solutions
+ Secure, efficient, and lightweight hardware implementations
+ Security of reconfigurable and adaptive hardware
+ Emerging computing technologies in security
+ New designs and materials in hardware security
+ Nanophysics and nanotechnology in hardware security
+ Physical unclonable functions and new/emerging variants thereof
+ Item tagging, secure supply chains, and product piracy
+ Intellectual property protection and content protection
+ Scalable hardware solutions for large numbers of players/endpoints
+ Hardware security and machine learning: Secure hardware implementations of machine learning algorithms, machine learning in side channel attacks, etc.
+ Hardware security in emerging application scenarios: Internet of Things, smart home, automotive and autonomous systems, wearable computing, pervasive and ubiquitous computing, etc.
+ Architectural factors and hardware security in the cloud
+ Electronic voting machines
+ Nuclear weapons inspections and control
+ Physical layer and wireless network security
+ Anti-forensic attacks and protection: Hardware virtualization, anti-forensic resilient memory acquisition, etc.
+ Mobile devices, smart cards, and chip cards
+ Architectural factors in hardware security, isolation versus encryption
+ Secure hardware for multiparty computation
+ Integration of hardware root of trust and PUFs
+ Quality metrics for secure hardware
+ Conformance and evaluation of secure hardware
+ Formal treatments, proofs, standardization, or categorization of hardware-related techniques





#	4th IEEE International Conference on Rebooting Computing

Part of IEEE Rebooting Computing Week
6-8 November 2019
San Francisco Bay Area, California
http://icrc.ieee.org/cfp/

The broad scope of ICRC extends to many areas of interest, including novel device physics and materials for post-Moore, beyond CMOS, and non-von Neumann computing paradigms.

Topics of interest
+ Future computing approaches, including neuromorphic, brain-inspired computing, approximate and probabilistic, analog computing; computing based on novel device physics and materials (e.g., spin-based electronics, nonlinear dynamics and chaos); energy-efficient computing including reversible, adiabatic, and ballistic computing, superconductor and cryogenic computing; quantum computing; optical computing; biological and biochemical computing; Non-von Neumann computer architectures (e.g., in-memory processing, memory-based computing, cellular automata, or cellular neural networks).
+ Future computing design aspects, including extending Moore’s law and augmenting CMOS; error-tolerant logic and circuits; future of design automation. post-CMOS, 3D, heterogeneous integration and packaging; future impact on performance, power, scalability, reliability, supportability
+ Future Software and Applications, including beyond von Neumann system software issues (operating systems, compilers, security, and resource management); future computing programming paradigms and languages; applications suitable for and driving next generation computing (e.g., machine learning, deep learning.)
+ Future computing use cases and prototypes, including ethics in design, implementation, and use; new technologies impacting the International Roadmap for Devices and Systems (IRDS); cybersecurity in future computing systems.





#	Low-Power Computer Vision Workshop 2019

https://rebootingcomputing.ieee.org/lpirc/low-power-computer-vision-workshop-2019

##	Solutions for Low-Power Computer Vision:

Computer vision technologies have made impressive progress in recent years, but often at the expense of increasingly complex models needing more and more computational and storage resources. This workshop aims to improve the energy efficiency of computer vision solutions for running on systems with stringent resources, for example, mobile phones, drones, or renewable energy systems. Efficient computer vision can enable many new applications (e.g., wildlife observation) powered by ambient renewable energy (e.g., solar, vibration, and wind). This workshop will discuss the state of the art of low-power computer vision, challenges in creating efficient vision solutions, promising technologies that can achieve the goals, methods to acquire and label data, benchmarks and metrics to evaluate progress and success. Authors are encouraged to present innovation in any part of the entire systems, such as new hardware components, new algorithms, new methods for system integration, new semiconductor devices, and new computing paradigms. This workshop emphasizes “system-level” solutions with implementations for demonstrations and experiments. Conceptual designs or solutions for individual components without integration into functional systems are discouraged.

Authors are encouraged to discuss the following issues in their papers:
+ Description of the solution
+ Description of the data for evaluation
+ Description of the system
+ Metrics for evaluation
+ Comparison with the state-of-the-art


##	Grand Challenges in Low-Power Computer Vision:

Competitions are widely adopted in academia, industry, and government to propel technologies forward. Well-known competitions include the DARPA Autonomous Vehicle Challenge and the Space X prize. The competitions have been attributed as the accelerators of making significant progress in the technologies. This workshop solicits papers that describe future competition of low-power computer vision. Authors are encouraged to think boldly, imagining “Grand Challenge” or “X Prize” type of competitions. The winners’ solutions (maybe hardware, software, or combination) should be far beyond today’s available technologies.

Authors are encouraged to discuss the following issues in their papers:
+ Description of the challenge and why it is worth the community’s efforts for several years
+ Description of the state-of-the-art (the challenge should be far beyond today’s technology but achievable)
+ Description the people that can benefit from the technologies
+ Description of the market size in billions per year (if applicable)
+ Description of the data (e.g., image, video, with or without caption, and others)
+ Methods to acquire the data and methods for scoring
+ Paths toward solving the problems. Do they need innovation in vision algorithms? Hardware? Software? Will non-traditional systems be needed? Why?
+ Description about copyright and privacy (if applicable)
+ Methods to annotate the data (if applicable, for getting the ground truth)
+ Constraints of hardware (if applicable, e.g., weight and size)
+ Minimum or maximum requirements (if applicable, e.g., accuracy and execution time)



+ Alexander C Berg, Associate Professor, University of North Carolina at Chapel Hill, aberg@cs.unc.edu
+ Bo Chen, Software Engineer, Google Inc. bochen@google.com
+ Yiran Chen, Associate Professor, Duke University, yiran.chen@duke.edu
+ Yen-Kuang Chen, Research Scientist, Alibaba, y.k.chen@ieee.org
+ Eui-Young Chung, Professor, Yonsei University, eychung@yonsei.ac.kr
+ Svetlana Lazebnik, Associate Professor, University of Illinois, slazebni@illinois.edu
+ (contact) Yung-Hsiang Lu, Professor, Purdue University, yunglu@purdue.edu
+ Sungroh Yoon, Associate Professor, Seoul National University, sryoon@snu.ac.kr







+ Y. Lu, A. M. Kadin, A. C. Berg, T. M. Conte, E. P. DeBenedictis, R. Garg, G. Gingade, B. Hoang, Y. Huang, B. Li, J. Liu, W. Liu, H. Mao, J. Peng, T. Tang, E. K. Track, J. Wang, T. Wang, Y. Wang, and J. Yao. Rebooting computing and low-power image recognition challenge. In 2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), pages 927–932, Nov 2015.
+ K. Gauen, R. Rangan, A. Mohan, Y. Lu, W. Liu, and A. C. Berg. Low-power image recognition challenge. In 2017 22nd Asia and South Pacific Design Automation Conference (ASP-DAC), pages 99–104, Jan 2017.
+ K. Gauen, R. Dailey, Y. Lu, E. Park, W. Liu, A. C. Berg, and Y. Chen. Three years of low-power image recognition challenge: Introduction to special session. In 2018 Design, Automation Test in Europe Conference Exhibition (DATE), pages 700–703, March 2018.
+ Sergei Alyamkin, Matthew Ardi, Achille Brighton, Alexander C. Berg, Yiran Chen, Hsin-Pai Cheng, Bo Chen, Zichen Fan, Chen Feng, Bo Fu, Kent Gauen, Jongkook Go, Alexander Goncharenko, Xuyang Guo, Hong Hanh Nguyen, Andrew Howard, Yuanjun Huang, Donghyun Kang, Jaeyoun Kim, Alexander Kondratyev, Seungjae Lee, Suwoong Lee, Junhyeok Lee, Zhiyu Liang, Xin Liu, Juzheng Liu, Zichao Li, Yang Lu, Yung-Hsiang Lu, Deeptanshu Malik, Eun-byung Park, Denis Repin, Tao Sheng, Liang Shen, Fei Sun, David Svitov, George K. Thiruvathukal, Baiwu Zhang, Jingchi Zhang, Xiaopeng Zhang, and Shaojie Zhuo. 2018 low-power image recognition challenge. CoRR, abs/1810.01732, 2018.
+ Yung-Hsiang Lu, Alexander C. Berg, and Yiran Chen. Low-power image recognition challenge. AI Magazine, 39(2), Summer 2018.


+ Understanding the Challenges of Algorithm and Hardware Co-design for Deep Neural Networks, Vivienne Sze (sze@mit.edu), MIT
+ Turbocharge Deep Learning Inference using Reconfigurable Platforms, Ashish Sirasao (asirasa@xilinx.com), Xilinx
+ Invited Speakers: Rethinking the Computations in Computer Vision (and the Hardware that Computes Them), Kurt Keutzer, Berkeley



#	MoRe 2019, 2nd International Workshop on Multi-objective Reasoning in Verification and Synthesis

+ MoRe aims at bringing together researchers interested in multi-objective reasoning for verification and synthesis.

Traditionally, verification and synthesis techniques focus on a single qualitative or quantitative objective for the reactive system. In practice, it is often desired that systems satisfy a functional requirement expressed as a qualitative property, while optimising some quantitative dimension (e.g., reach a target state while minimising the energy consumption). Furthermore, there are numerous application contexts in which reasoning simultaneously about multiple, heterogeneous quantitative and qualitative characteristics is important. In many cases, the analysis of such systems may be complicated by the fact that there are trade-offs between objectives. Such trade-offs may also arise between several interpretations of the same quantitative dimension: for example, between the average-case and the worst-case performance of a system.

MoRe is a meeting place for researchers in the area of multi-objective reasoning for verification and synthesis, with topics of interest ranging from novel theoretical models to industrial challenges and practical applications. Typical topics of the workshop include, but are not limited to, formal approaches toward verification and synthesis in the following settings:

+ games (and related models) with multiple qualitative and quantitative objectives;
+ multi-criteria reasoning in probabilistic models (e.g., percentile queries, quantiles, trade-off between worst-case and average-case performance);
+ extensions of timed automata including probabilistic or weighted aspects;
+ stochastic hybrid systems;
+ temporal logics enabling quantitative reasoning;
+ probabilistic programs;
+ practical applications involving multi-objective challenges;
+ any related attempt to tackle trade-offs between multiple criteria in formal models for verification and synthesis.




# DSAA, IEEE/ACM/ASA DSAA, IEEE International Conference on Data Science and Advanced Analytics

+ Foundations: Models and algorithms; asymptotic analysis; model evaluation, selection and model averaging; dimensionality reduction; strategies for handling missing data; relational/structured learning; matrix and tensor methods; deep learning; time series, spatial, or grouped data; feature/covariate selection and regularization; nonparametric Bayesian methods; computational methods for Bayesian inference; manifold learning, classification, clustering, regression; semi-supervised and unsupervised learning; personalization, security, privacy; visualization; optimization, inference and regularization; social network analysis.
+ Infrastructure: Large-scale databases; cloud computing; big-data engineering and processing; large-scale processing and distributed/parallel computing; human-machine interaction; storage, search, and retrieval.
+ Social Issues: Reproducibility and replicability; model explainability and provenance; data quality and model quality; bias and unintended consequences of algorithms and results; p-hacking and data dredging; publication bias and pre-analysis plans; trust, risk, and informed consent; data integrity and data ethics; matching, record linkage, and sharing; de-identification and re-identification; generalizability of results; causal inference.


+ This track solicits high-quality, original papers describing applications of Data Science and Advanced Analytics across various disciplines and domains, including business, government, health and medical science, physical sciences, and social sciences. The focus is on papers that would be of interest to practitioners of Data Science and Advanced Analytics, or would highlight new challenges for researchers driven by the specific needs and characteristics of application areas. Topics of interest include but are not limited to:
+ Case Studies describing work on a real-world problem using Data Science and Advanced Analytics that highlight important application domain-specific discoveries, lessons learned and/or challenges encountered from deploying real-world systems containing Data Science and Advanced Analytics approaches, data science and analysis-related ethical issues and solution approaches related to real-world applications.
+ Infrastructure, Platforms, and Tools that were built to operationalize Data Science and Advanced Analytics, including the development and deployment of new hardware and software infrastructure and its associated challenges; the development, deployment, and use of reusable libraries and software implementations; and tools that are in production and are used by end-users either in a stand-alone capacity or as part of a business process.
+ Submissions for both the research and applications tracks  should very clearly specify the problem being solved, what methodologies were used to solve the problem, what data was used, how the results were evaluated, and how the solution is being used (ideally in production). Applying new data science methods to public data or data downloaded from competition sites (such as kaggle), without a real problem (and problem owner) will not be accepted in this track.
