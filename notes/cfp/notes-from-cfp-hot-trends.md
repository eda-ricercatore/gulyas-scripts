#	Workshop on Parallel AI and Systems for the Edge

From: https://www.sigarch.org/call-contributions/workshop-on-parallel-ai-and-systems-for-the-edge/

1st Workshop on Parallel AI and Systems for the Edge (PAISE)
in conjunction with IPDPS 2019
Rio de Janeiro, Brazil
May 24, 2019

IMPORTANT DATES:
Submission deadline: February 1, 2019
Notification of acceptance: March 1, 2019:
Workshop camera-ready papers due: March 11, 2019

For this workshop we welcome original work covering different aspects of:
1.Edge Inference
2.Hardware for Edge-computing and Machine Learning
3.Energy Efficient Processors for Training and Inference
4.Computer Vision at the Edge
5.Cyber Security for Edge Computing
6.Software and Hardware Multitenancy at the Edge
7.Machine Learning Hardware
8.Blockchains for Edge Computing
9.Programming Models for Edge Computing
10.Coupling HPC to Edge Applications
11.Communication and Control Strategies for Deploying and Managing Applications at the Edge

SUBMISSION GUIDELINES:
All papers must be original and not simultaneously submitted to another journal or conference. The papers submitted to the workshop will be peer reviewed by a minimum of 3 reviewers.

The following paper categories are welcome:
– Full Papers: Research papers should describe original work and be 8 or 10 pages in length.
– Short Papers: Short research papers, 4 pages in length, should contain enough information for the program committee to understand the scope of the project and evaluate the novelty of the problem or approach.
– Emerging Platforms and Practitioner Reports: Short reports, 3-6 pages in length, describing novel hardware and Software platforms, including initial proof-of-concept design and implementation are welcome. Reports may also focus on a particular aspect of technology usage in practice, or describe broad project experiences. They may describe a particular design idea, or experience with a particular piece of technology.

Templates for MS Word and LaTeX provided by IEEE eXpress Conference Publishing are available for download. See the latest versions here: https://www.ieee.org/conferences_events/conferences/publishing/templates.html

Upload your submission to EasyChair submission server in PDF format. EasyChair URL: https://easychair.org/cfp/PAISE2019.
Accepted manuscripts will be included in the IPDPS workshop proceedings.

ORGANIZERS:
Pete Beckman, Argonne National Laboratory, USA
Rajesh Sankaran, Argonne National Laboratory, USA


##	From the official web page

From: https://www.mcs.anl.gov/research/projects/waggle/cfp/PAISE2019.html

Applications involving voluminous data but needing low-latency computation and local feedback require that the computing be performed as close to the data source as possible --- often at the interface to the physical world. Communication constraints and the need for privacy-preserving approaches also dictate the need for computing at the edge. Given the growth in such application scenarios and the recent advances in algorithms and techniques, machine learning and inference at the edge are unfolding and growing at a rapid pace. In support of these applications, a wide range of hardware (CPUs, GPUs, ASICs) is venturing farther away from the center, closer to the physical world. The resulting diversity in edge-computing hardware in terms of capabilities, architectures, and programming models poses several new challenges.

At the edge, several applications often need to be scheduled concurrently or serially. Some applications may need to be run continuously, a few in anticipation of certain events, whereas others may need to be run when particular events occur, causing a need to unload other applications and dedicate resources to them. Situations may also warrant running applications in sandboxes for privacy, security, and resource allocation reasons. A future with heterogeneous edge hardware and multiple applications sharing the hardware and energy resources is imminent.

Deploying and managing applications at the edge remotely, and building in multienancy to support applications with various resource constraints and runtime requirements, present a challenge that requires cooperation and coordination between the various components of the software stack. Mechanisms need to be devised that communicate both data and control with the applications in order to fine-tune their behavior and change the operational parameters. Coupling these edge applications with centrally located HPC resources and their applications, realizing the computing continuum, also opens up many research areas.

As we push more toward edge-enabled networks of devices, we inherit a setting where resources are deployed away from the safety of secure indoor spaces, often in the midst of a bustling urban canyon, and exposed to physical and cybersecurity threats. Deployed and interconnected predominantly over public networks, these systems have to be designed with cybersecurity as a first-class design citizen, rather than introduced as an afterthought.

The goal of this workshop is to gather the community working in three broad areas:

+ processing — artificial intelligence, computer vision, machine learning;
+ management — parallel and distributed programming models for resource-constrained and domain-specific hardware, containers, remote resource management, runtime-system design, and cybersecurity; and
+ hardware — systems and devices conducive to use in resource-constrained (energy, space, etc.) applications.

The workshop will provide a critically needed opportunity to discuss the current trends and issues, to share visions, and to present solutions.

Topics

For this workshop we welcome original work covering different aspects of:

+ Edge Inference
+ Hardware for Edge-computing and Machine Learning
+ Energy Efficient Processors for Training and Inference
+ Computer Vision at the Edge
+ Cyber Security for Edge Computing
+ Software and Hardware Multitenancy at the Edge
+ Machine Learning Hardware
+ Blockchains for Edge Computing
+ Programming Models for Edge Computing
+ Coupling HPC to Edge Applications
+ Communication and Control Strategies for Deploying and Managing Applications at the Edge



#	FastPath: Workshop on Performance Analysis of Machine Learning Systems

https://www.sigarch.org/call-contributions/workshop-on-performance-analysis-of-machine-learning-systems/

Call for Papers:
FastPath: Workshop on Performance Analysis of Machine Learning Systems

March 24, 2019 in Madison, Wisconsin, USA
URL: https://tinyurl.com/2019-FastPath
Abstract or Paper Registration Deadline
February 8, 2019
Final Submission Deadline
February 8, 2019

FastPath: International Workshop on Performance Analysis of Machine Learning Systems
in conjunction with ISPASS 2019
Madison, Wisconsin, USA
March 24, 2019

FastPath 2019 brings together researchers and practitioners involved in cross-stack hardware/software performance analysis, modeling, and evaluation for efficient machine learning systems. Machine learning demands tremendous amount of computing. Current machine learning systems are diverse, including cellphones, high performance computing systems, database systems, self-driving cars, robotics, and in-home appliances. Many machine-learning systems have customized hardware and/or software. The types and components of such systems vary, but a partial list includes traditional CPUs assisted with accelerators (ASICs, FPGAs, GPUs), memory accelerators, I/O accelerators, hybrid systems, converged infrastructure, and IT appliances. Designing efficient machine learning systems poses several challenges.

These include distributed training on big data, hyper-parameter tuning for models, emerging accelerators, fast I/O for random inputs, approximate computing for training and inference, programming models for a diverse machine-learning workloads, high-bandwidth interconnect, efficient mapping of processing logic on hardware, and cross system stack performance optimization. Emerging infrastructure supporting big data analytics, cognitive computing, large-scale machine learning, mobile computing, and internet-of-things, exemplify system designs optimized for machine learning at large.

FastPath seeks to facilitate the exchange of ideas on performance optimization of machine learning/AI systems and seeks papers on a wide range of topics including, but not limited to:
– Workload characterization, performance modeling and profiling of machine learning applications
– GPUs, FPGAs, ASIC accelerators
– Memory, I/O, storage, network accelerators
– Hardware/software co-design
– Efficient machine learning algorithms
– Approximate computing in machine learning
– Power/Energy and learning acceleration
– Software, library, and runtime for machine learning systems
– Workload scheduling and orchestration
– Machine learning in cloud systems
– Large-scale machine learning systems
– Emerging intelligent/cognitive system
– Converged/integrated infrastructure
– Machine learning systems for specific domains, e.g., financial, biological, education, commerce, healthcare

SUBMISSION GUIDELINES:
Prospective authors must submit a 2-4 page extended abstract electronically at: https://easychair.org/conferences/?conf=fastpath2019

Authors of selected abstracts will be invited to give a 30-min presentation at the workshop.

IMPORTANT DATES:
Submission: February 8, 2019
Notification: February 22, 2019
Final Materials / Workshop: March 24, 2019

ORGANIZERS:
General Chair:
Erik Altman

Program Committee Chairs:
Zehra Sura
Parijat Dube


##	From the Official Web Page

https://researcher.watson.ibm.com/researcher/view_group.php?id=9888

FastPath 2019
International Workshop on Performance
Analysis of Machine Learning Systems
March 24, 2019 - Madison, Wisconsin, USA
In conjunction with ISPASS 2019
https://tinyurl.com/2019-FastPath

FastPath 2019 Program:  Pending

FastPath 2019 brings together researchers and practitioners involved in cross-stack hardware/software performance analysis, modeling, and evaluation for efficient machine learning systems. Machine learning demands tremendous amount of computing. Current machine learning systems are diverse, including cellphones, high performance computing systems, database systems, self-driving cars, robotics, and in-home appliances. Many machine-learning systems have customized hardware and/or software. The types and components of such systems vary, but a partial list includes traditional CPUs assisted with accelerators (ASICs, FPGAs, GPUs), memory accelerators, I/O accelerators, hybrid systems, converged infrastructure, and IT appliances. Designing efficient machine learning systems poses several challenges.

These include distributed training on big data, hyper-parameter tuning for models, emerging accelerators, fast I/O for random inputs, approximate computing for training and inference, programming models for a diverse machine-learning workloads, high-bandwidth interconnect, efficient mapping of processing logic on hardware, and cross system stack performance optimization. Emerging infrastructure supporting big data analytics, cognitive computing, large-scale machine learning, mobile computing, and internet-of-things, exemplify system designs optimized for machine learning at large.


Topics

FastPath seeks to facilitate the exchange of ideas on performance analysis and evaluation of machine learning/AI systems and seeks papers on a wide range of topics including, but not limited to:

+ Workload characterization, performance modeling and profiling of machine
+ learning applications
+ GPUs, FPGAs, ASIC accelerators
+ Memory, I/O, storage, network accelerators
+ Hardware/software co-design
+ Efficient machine learning algorithms
+ Approximate computing in machine learning
+ Power/Energy and learning acceleration

+ Software, library, and runtime for machine learning systems
+ Workload scheduling and orchestration
+ Machine learning in cloud systems
+ Large-scale machine learning systems
+ Emerging intelligent/cognitive systems
+ Converged/integrated infrastructure
+ Machine learning systems for specific domains, e.g., financial, biological, education, commerce, healthcare


Submission

FastPath 2019 Call for Papers is available here.

Prospective authors must submit a 2-4 page extended abstract electronically at:

https://easychair.org/conferences/?conf=fastpath2019

Authors of selected abstracts will be invited to give a 30-min presentation at the workshop.


Key Dates

+ Submission: February 8, 2019
+ Notification: February 22, 2019
+ Final Materials / Workshop: March 24, 2019


Organizers

+ General Chair: Erik Altman (IBM)
+ Program Committee Chairs: Zehra Sura (IBM), Parijat Dube (IBM)


Program Committee
TBD: TBD Institution

Invited Speakers:

Tushar Krishna: Georgia Tech

Peter Mattson: Google

Vijay Janapa Reddi: Harvard


Previous Editions

FastPath 2018 was held in conjunction with ISPASS 2018. Full-day with 4 invited speakers and panel.

FastPath 2015 was held in conjunction with ISPASS 2015. Half-day with 4 invited speakers.

FastPath 2014 was held in conjunction with ISPASS 2014. Full-day with 3 invited speakers and 4 Regular speaker.

FastPath 2013 was held in conjunction with ISPASS 2013. Full-day with 1 keynote speaker, 6 invited speakers and 1 Regular speaker.

FastPath 2012 was held in conjunction with ISPASS 2012. Half-day with 1 keynote speaker and 3 invited speakers.



#	Workshop on Attacks and Solutions in Hardware Security (ASHES 2019)

+ Fault injection, side channels, hardware Trojans, and countermeasures
+ Tamper sensing and tamper protection
+ New physical attack vectors or methods
+ Biometrics
+ Secure sensors
+ Device fingerprinting and hardware forensics
+ Lightweight hardware solutions
+ Secure, efficient, and lightweight hardware implementations
+ Security of reconfigurable and adaptive hardware
+ Emerging computing technologies in security
+ New designs and materials in hardware security
+ Nanophysics and nanotechnology in hardware security
+ Physical unclonable functions and new/emerging variants thereof
+ Item tagging, secure supply chains, and product piracy
+ Intellectual property protection and content protection
+ Scalable hardware solutions for large numbers of players/endpoints
+ Hardware security and machine learning: Secure hardware implementations of machine learning algorithms, machine learning in side channel attacks, etc.
+ Hardware security in emerging application scenarios: Internet of Things, smart home, automotive and autonomous systems, wearable computing, pervasive and ubiquitous computing, etc.
+ Architectural factors and hardware security in the cloud
+ Electronic voting machines
+ Nuclear weapons inspections and control
+ Physical layer and wireless network security
+ Anti-forensic attacks and protection: Hardware virtualization, anti-forensic resilient memory acquisition, etc.
+ Mobile devices, smart cards, and chip cards
+ Architectural factors in hardware security, isolation versus encryption
+ Secure hardware for multiparty computation
+ Integration of hardware root of trust and PUFs
+ Quality metrics for secure hardware
+ Conformance and evaluation of secure hardware
+ Formal treatments, proofs, standardization, or categorization of hardware-related techniques
