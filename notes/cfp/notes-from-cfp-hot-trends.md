#	Workshop on Parallel AI and Systems for the Edge

From: https://www.sigarch.org/call-contributions/workshop-on-parallel-ai-and-systems-for-the-edge/

1st Workshop on Parallel AI and Systems for the Edge (PAISE)
in conjunction with IPDPS 2019
Rio de Janeiro, Brazil
May 24, 2019

IMPORTANT DATES:
Submission deadline: February 1, 2019
Notification of acceptance: March 1, 2019:
Workshop camera-ready papers due: March 11, 2019

For this workshop we welcome original work covering different aspects of:
1.Edge Inference
2.Hardware for Edge-computing and Machine Learning
3.Energy Efficient Processors for Training and Inference
4.Computer Vision at the Edge
5.Cyber Security for Edge Computing
6.Software and Hardware Multitenancy at the Edge
7.Machine Learning Hardware
8.Blockchains for Edge Computing
9.Programming Models for Edge Computing
10.Coupling HPC to Edge Applications
11.Communication and Control Strategies for Deploying and Managing Applications at the Edge

SUBMISSION GUIDELINES:
All papers must be original and not simultaneously submitted to another journal or conference. The papers submitted to the workshop will be peer reviewed by a minimum of 3 reviewers.

The following paper categories are welcome:
– Full Papers: Research papers should describe original work and be 8 or 10 pages in length.
– Short Papers: Short research papers, 4 pages in length, should contain enough information for the program committee to understand the scope of the project and evaluate the novelty of the problem or approach.
– Emerging Platforms and Practitioner Reports: Short reports, 3-6 pages in length, describing novel hardware and Software platforms, including initial proof-of-concept design and implementation are welcome. Reports may also focus on a particular aspect of technology usage in practice, or describe broad project experiences. They may describe a particular design idea, or experience with a particular piece of technology.

Templates for MS Word and LaTeX provided by IEEE eXpress Conference Publishing are available for download. See the latest versions here: https://www.ieee.org/conferences_events/conferences/publishing/templates.html

Upload your submission to EasyChair submission server in PDF format. EasyChair URL: https://easychair.org/cfp/PAISE2019.
Accepted manuscripts will be included in the IPDPS workshop proceedings.

ORGANIZERS:
Pete Beckman, Argonne National Laboratory, USA
Rajesh Sankaran, Argonne National Laboratory, USA


##	From the official web page

From: https://www.mcs.anl.gov/research/projects/waggle/cfp/PAISE2019.html

Applications involving voluminous data but needing low-latency computation and local feedback require that the computing be performed as close to the data source as possible --- often at the interface to the physical world. Communication constraints and the need for privacy-preserving approaches also dictate the need for computing at the edge. Given the growth in such application scenarios and the recent advances in algorithms and techniques, machine learning and inference at the edge are unfolding and growing at a rapid pace. In support of these applications, a wide range of hardware (CPUs, GPUs, ASICs) is venturing farther away from the center, closer to the physical world. The resulting diversity in edge-computing hardware in terms of capabilities, architectures, and programming models poses several new challenges.

At the edge, several applications often need to be scheduled concurrently or serially. Some applications may need to be run continuously, a few in anticipation of certain events, whereas others may need to be run when particular events occur, causing a need to unload other applications and dedicate resources to them. Situations may also warrant running applications in sandboxes for privacy, security, and resource allocation reasons. A future with heterogeneous edge hardware and multiple applications sharing the hardware and energy resources is imminent.

Deploying and managing applications at the edge remotely, and building in multienancy to support applications with various resource constraints and runtime requirements, present a challenge that requires cooperation and coordination between the various components of the software stack. Mechanisms need to be devised that communicate both data and control with the applications in order to fine-tune their behavior and change the operational parameters. Coupling these edge applications with centrally located HPC resources and their applications, realizing the computing continuum, also opens up many research areas.

As we push more toward edge-enabled networks of devices, we inherit a setting where resources are deployed away from the safety of secure indoor spaces, often in the midst of a bustling urban canyon, and exposed to physical and cybersecurity threats. Deployed and interconnected predominantly over public networks, these systems have to be designed with cybersecurity as a first-class design citizen, rather than introduced as an afterthought.

The goal of this workshop is to gather the community working in three broad areas:

+ processing — artificial intelligence, computer vision, machine learning;
+ management — parallel and distributed programming models for resource-constrained and domain-specific hardware, containers, remote resource management, runtime-system design, and cybersecurity; and
+ hardware — systems and devices conducive to use in resource-constrained (energy, space, etc.) applications.

The workshop will provide a critically needed opportunity to discuss the current trends and issues, to share visions, and to present solutions.

Topics

For this workshop we welcome original work covering different aspects of:

+ Edge Inference
+ Hardware for Edge-computing and Machine Learning
+ Energy Efficient Processors for Training and Inference
+ Computer Vision at the Edge
+ Cyber Security for Edge Computing
+ Software and Hardware Multitenancy at the Edge
+ Machine Learning Hardware
+ Blockchains for Edge Computing
+ Programming Models for Edge Computing
+ Coupling HPC to Edge Applications
+ Communication and Control Strategies for Deploying and Managing Applications at the Edge
